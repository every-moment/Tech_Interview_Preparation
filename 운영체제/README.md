# 운영체제   

## 1. 프로세스 vs 스레드
</br>

프로그램: 코드가 구현되어 있는 파일 (어떤 작업을 위해 실행할 수 있는 파일)     
프로세스: 실행중인 프로그램. 디스크 -> 메모리로 적재되어 CPU의 할당을 받은 작업의 단위     
</br>
</br>
 
프로그램 -> 프로세스가 되면서 일어나는 일 2가지    
</br>

1. 프로세스가 필요로하는 재료들이 메모리에 올라간다.      
그 메모리는 4가지 영역으로 나뉘어 있다.      
 - Code 영역: 실행 명령을 포함하는 코드들      
 - Data 영역: Static 영역 혹은 Global 변수      
 - Heap 영역: 동적 메모리 영역      
 - Stack 영역: 지역변수, 매개변수, 리턴 값 등의 일시적인 데이터
</br>

2. 해당 프로세스에 대한 정보를 담고 있는 PCB 블럭이 생성된다.      
 - Pointer: 프로세스상태 중에 준비상태나 대기상태의 큐를 구현하기 위해 필요한 포인터      
 - Process State: 현재 프로세스의 상태를 담음      
 - PID: 프로세스의 고유번호를 담음      
 - PC(Program Counter): 다음 명령어를 가리킴      
</br>

스레드: 프로세스의 실행 단위. 하나의 프로세스 안에서 자원(코드,데이터,힙 영역)을 공유한다. 각 스레드는 스택 영역만을 따로 가지고 있다. 공유되는 자원이 있기 때문에 컨텍스트 스위칭이 일어날 때 캐싱 적중률이 올라간다.      
</br>

멀티프로세스 vs 멀티스레드      
둘 다 한 어플리케이션에 대한 [처리 방식]이라고 이해를 하자.      
</br>

멀티프로세스      
 - 각 프로세스는 독립적          
 - IPC(Inter-Process Communication)로 통신     
 - 자원 소모적, 개별 메모리 차지
 - 컨텍스트 스위칭 비용이 큼     
 - 한 프로세스에 문제가 생겨도 다른 프로세스에는 영향이 가지 않음     
 
멀티스레드
 - 스레드끼리 긴밀하게 연결되어 있음     
 - 공유된 자원으로 통신 비용 절감     
 - 공유된 자원으로 메모리가 효율적
 - 컨텍스트 비용이 적음     
 - 공유 자원 관리를 해야함     
 - 한 스레드에 문제가 생기면 전체 프로세스에 영향이 감     
    
</br>

멀티코어     
 - 멀티프로세스와 멀티스레드는 처리방식의 일종이기 떄문에 소프트웨어분야에 가깝고     
 - 멀티코어는 조금 더 하드웨어의 측면에 가깝다.
 - 멀티코어에 관련된 키워드: 동시성, 병렬처리
    - 동시성(Concurrency): 하나의 코어에서 하나 이상의 프로세스 혹은 스레드가 번갈아가면서 진행되지만 동시에 진행되는 것 처럼 보이는 것(멀티프로세스,멀티스레드)     
    - 병렬처리(Parallelism): 둘 이상의 코어에서 동시에 하나 이상의 프로세스(혹은 스레드)가 한꺼번에 진행되는 것(멀티코어)     
 
 ---           
 
## CPU 스케줄링    
</br>

하나의 프로세스 작업이 끝나면 CPU가 다음 프로세스를 실행해야 한다. 이렇게 다음 프로세스를 선택하는 알고리즘을 CPU 스케줄링 알고리즘이라고 한다      
CPU가 일을 수행하는 시간: CPU burst time     
Ready Queue: 현재 메모리 내에 있으면서 CPU 를 잡아서 실행되기를 기다리는 프로세스의 집합.   
</br>

### Preemptive vs Non-Preemptive      
</br>

1. Preemptive(선점)      
 - 프로세스가 CPU를 점유하고 있는 동안 I/O나 인터럽트가 발생하지 않았음에도 다른 프로세스가 해당 CPU를 강제로 점유할 수 있다      
 - 즉, 프로세스가 정상적으로 수행중인 동안 다른 프로세스가 CPU를 강제로 점유하여 실행할 수 있다      
 
2. Non-Preemptive(비선점)
 - 한 프로세스가 CPU를 점유했으면 I/O나 인터럽트가 발생 혹은 프로세스가 종료될 때까지 다른 프로세스가 CPU를 점유하지 못하는 것이다      
 
    
### 선점형 스케줄링      
1. SRT(Shortest Remaining Time) 혹은 SRTF(Shortest Remaining Time First)       
 - 현재 수행중인 프로세스의 남은 burst time 보다 더 짧은 CPU burst time 을 가지는 새로운 프로세스가 도착하면 CPU를 선점한다      
 - 새로운 프로세스가 Ready Queue에 도착할 때마다 새로운 스케줄링이 이루어진다      
 - 문제점
    - starvation(프로세스가 끊임없이 필요한 컴퓨터 자원을 가져오지 못하는 상황)     
</br>
    
2. Round Robin      
 - 시분할 시스템의 성질을 활용한 방법      
 - 일정 시간을 정하여 하나의 프로세스가 이 시간동안 실행하고 ready queue의 제일 뒤에 가서 다시 줄을 선다     
 - 그리고 다음 프로세스 역시 같은 시간동안 수행한 후, 대기한다. 이러한 작업을 모든 프로세스가 돌아가면서 진행하며, 마지막 프로세스가 끝나면 다시 처음 프로세스로 돌아와서 작업을 반복한다     
 - 일정 시간을 Time Quantum(Time Slice)라고 부른다. 일반적으로 10 ~ 100msec 사이의 범위를 갖는다     
 - 한 프로세스가 종료되기 전에 time quantum이 끝나면 다른 프로세스에게 CPU를 넘겨주기 때문에 선점형 스케줄링     
 - RR은 CPU 사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적     
</br>
 
3. Multi-level Queue 스케줄링           
 - Ready Queue 여러 개로 분할해 관리하는 스케줄링 방법
 - 각 큐마다 다른 규칙을 지정할 수도 있다.(ex. 우선순위, CPU 시간 등)   
</br>

4. Multi-level feedback Queue 스케줄링
 - 기본 개념은 Multi-level Queue와 동일하나, 프로세스가 하나의 큐에서 다른 큐로 이동 가능하다는 점이 다르다    
</br>

### 비선점형 스케줄링    
1. FCFS(First Come First Server)     
 - 레디 큐에 먼저 도착한 프로세스가 CPU를 점유    
 - CPU를 할당받으면 CPU 버스트가 완료될 때까지 CPU를 반환하지 않으며, 할당되었던 CPU가 반환될 때만 스케줄링이 이루어진다     
 - 단점
    - Convoy Effect 발생 : 소요 시간이 긴 프로세스가 짧은 프로세스보다 먼저 도착해서 뒤에 프로세스들이 오래 기다려야 하는 현상     
</br>

2. SJF (Shortest Job First)     
 - 다른 프로세스가 먼저 도착했더라도 CPU 버스트가 짧은 프로세스에게 CPU를 먼저 할당하는 방식     
 - FCFS 보다 평균 대기 시간 감소     
 - 단점
    - starvation     
</br>

3. HRN (Hightest Response-ratio Next)           
 - 처리 시간이 긴 작업과 짧은 작업 사이의 차별이 발생하는 것을 보완하는 방식(SJF의 단점 보완)     
 - 우선순위 = (대기시간 + 실행시간) / (실행시간)     
</br>

Priority Scheduling (선점, 비선점 둘 다 가능)      
 - 우선순위가 가장 높은 프로세스에게 CPU 를 할당하는 스케줄링이다. 우선순위란 정수로 표현하게 되고 작은 숫자가 우선순위가 높다.     
 - 선점형 스케줄링(Preemptive) 방식
    - 더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU 를 선점한다.    
 - 비선점형 스케줄링(Non-Preemptive) 방식   
    - 더 높은 우선순위의 프로세스가 도착하면 Ready Queue 의 Head 에 넣는다.    
 - 문제점
    - starvation    
    - 해결책     
        - aging: ready queue에서 기다리는 동안 일정 시간이 지나면 우선 순위를 일정량 높여주는 것    
</br>
       
## 가상메모리

 - 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법     
 - 프로그램이 메모리보다 커도 된다    
 - 프로그램의 일부분만 메모리에 올리는 것이 핵심
 - 가상 메모리는 실제의 물리 메모리 개념과 논리 메모리 개념을 분리한 것 -> 작은 메모리를 가지고도 얼마든지 큰 가상 주소 공간을 프로그래머에게 제공할 수 있다
</br> 

가상 주소 공간
 - 한 프로세스가 물리 메모리에 저장되는 논리적인 모습을 가상메모리에 구현한 공간 -> 가상메모리 공간은 보조기억장치 공간을 이용한다
 - 프로세스가 요구하는 물리 메모리 공간을 가상메모리에서 제공함
 - 현재 직접적으로 필요치 않은 메모리 공간은 실제 물리 메모리에 올리지 않음으로써 물리 메모리를 절약할 수 있다
 - 예를 들어, 한 프로그램이 실행되며 논리 메모리로 100KB 가 요구됨
 - but, 실행까지에 필요한 메모리 공간(Heap영역, Stack 영역, 코드, 데이터)의 합이 40KB
 - 나머지 60KB 만큼은 필요시에 물리메모리에 요구하는 방식
</br>
 
요구 페이징(Demand paging)
 - 요구되는 페이지만 메모리에 올린다는 의미
 - 프로그램 실행 시작 시에 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략
 - 프로세스는 페이지의 조합이기 때문에 필요한 페이지만 메모리에 올린다
 - 프로세스 내의 개별 페이지들은 페이저(pager)에 의해 관리된다
 - 페이저는 프로세스 실행에 실제 필요한 페이지들만 메모리로 읽어옴으로써, 사용되지 않을 페이지를 가져오는 시간낭비와 메모리 낭비를 줄일 수 있다
</br>

### 페이징 vs 세그멘테이션
 
 - 둘다 가상메모리를 관리하는 기법
</br>
 
페이징
 - 프로세스의 주소 공간을 고정된 크기의 페이지 단위로 나누어 물리적 메모리에 불연속적으로 저장하는 방식
 - 메모리는 Frame이라는 고정 크기로 분할되고, 프로세스는 Page라 불리는 고정 크기로 분할된다.
 - 프로세스를 정상적으로 사용하기 위해 MMU의 재배치 레지스터를 여러 개 사용해서 각 페이지의 실제 주소로 변경해준다. 이러한 여러 개의 재배치 레지스터를 페이지 테이블(Page Table)이라 한다.     
 - 요구 페이징 기법을 사용하면 페이지가 메모리에 올라와있는 것도 있고 가상메모리에 있는 것도 존재한다. 따라서 페이지 테이블을 작성할 때 이를 구분해줄 도구가 필요하다. 그래서 valid bit 필드를 페이지 테이블에 추가한다. 1과 0의 값으로 메모리에 적재되어 있는지 없는지를 구분할 수 있다.     
 - 페이지 테이블에는 페이지 번호, 프레임의 시작 주소, vaild bit 등이 존재.   
</br>
 
내부 단편화
 - 프로세스 크기가 페이지 크기의 배수가 아닐 경우
 - 마지막 페이지는 한 페이지를 다 채울 수 없어서 발생하는 공간으로 메모리 낭비의 원인이 된다. 
</br>

외부 단편화
 - 메모리 공간 중 사용하지 못하게 되는 일부분
 - 메모리에서 사이사이 남는 공간들을 모두 합치면 충분한 공간이 되는 부분들이 분산되어 있을때 발생한다고 볼 수 있다.
</br>

페이지의 크기가 작을 수록
 - 더 많은 페이지 테이블의 공간이 필요
 - 페이지 폴트가 많아져서 보조기억장치에 접근하는 횟수가 많아져서 전체적인 입출력시간이 늘어남
 - 내부 단편화는 줄어듦
 - 스레싱이 발생할 수 있음
    - 스레싱: 하드디스크의 입출력이 너무 많아져 잦은 페이지 폴트로 프로세스 수행시간보다 페이지 교체 시간이 많은 상태
</br>

페이지의 크기가 클 수록
 - 페이지 테이블의 크기가 작아짐
 - 보조기억장치에 접근하는 횟수가 적어져서 전체적인 입출력시간이 줄어듦
 - 내부 단편화가 증가됨
 - 프로세스 수행에 불필요한 내용까지 주기억장치에 적재될 수 있음
</br>
    
세그멘테이션
 - 프로세스를 서로 크기가 다른 논리적인 블록 단위인 세그먼트로 분할하고 메모리에 배치하는 것
 - 각 세그먼트의 크기는 일정하지 않다.
 - 세그먼테이션은 페이징과 유사하지만, 현재 대부분은 페이징 기법을 사용한다. 그 이유는 세그먼테이션에는 치명적인 단점이 존재하기 때문이다.    
 - 세그먼테이션은 논리적인 단위로 나누기 때문에 세그먼트의 크기가 다양하다 -> 따라서 외부단편화로 인해 메모리 낭비가 크다
</br>
 
 
페이지 교체
 - 요구 페이징을 사용하면 프로그램 실행시에 모든 항목이 물리 메모리에 올라오지 않는다
 - 프로세스의 동작에 필요한 페이지를 요청하는 과정에서 page fault(페이지 부재)가 발생하게 되면, 원하는 페이지를 보조저장장치에서 가져오게 된다. 
 - 이때, 물리 메모리가 모두 사용중인 상황이라면, 페이지 교체가 이뤄져야 한다
 - 현재 메모리에 올라와있는 페이지 중 어떤 것을 교체할지 결정하는 방법을 페이지 교체 알고리즘이라 한다
</br>

페이지 교체 알고리즘

 - FIFO(First In First Out)
    - 페이지 교체시 메모리에 먼저 올라온 페이지를 먼저 내보내는 알고리즘
    - 페이지의 향후 참조 가능성을 고려하지 않기 때문에 비효율적인 상황이 발생할 수 있음
 - 최적 페이지 교체(Optimal Page Replacement)
    - 앞으로 가장 오랫동안 사용하지 않은 페이지를 교체하는 방법
    - 미래에 어떤 페이지가 어떠한 순서로 참조될지 미리 알고있다는 전제하에 알고리즘을 운영하므로 현실적으로 구현이 어렵다.
 - LRU (Least Recently Used)
    - 최근에 사용하지 않은 페이지를 가장 먼저 내보내는 방법
    - 실제로 사용할 수 있는 페이지 교체 알고리즘에서는 가장 좋은 방법 중 하나
 - LFU (Least Frequently Used)
    - 페이지의 참조 횟수로 교체할 페이지를 결정하는 방법
    - 페이지 중 과거에 참조 횟수가 가장 적었던 페이지를 내쫓고 그 자리에 새로 참조될 페이지를 적재한다
    - 시간에 따른 페이지 참조의 변화를 반영하지 못하고 LRU보다 구현이 복잡하다는 단점이 있음

        
           
    
 
